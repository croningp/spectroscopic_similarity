{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from AnalyticalLabware.analysis.spinsolve_spectrum import SpinsolveNMRSpectrum\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HERE = os.path.abspath(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectrum = SpinsolveNMRSpectrum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_code = \"RR-M3-5bb-moni-v3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import linregress\n",
    "\n",
    "\n",
    "def detect_plateau_from_slope(\n",
    "    times, values, num_datapoints: int = 5, threshold: float = 1e-4\n",
    ") -> tuple:\n",
    "    \"\"\"\n",
    "    Detects a plateau in a list of values by calculating the slope of a linear regression\n",
    "    for the last num_datapoints and comparing it to a threshold value.\n",
    "    \"\"\"\n",
    "    for i in range(len(values) - num_datapoints):\n",
    "        if i < num_datapoints:\n",
    "            continue\n",
    "        slope = linregress(\n",
    "            range(num_datapoints),\n",
    "            np.array(values[i - num_datapoints : i]) / max(values),\n",
    "        ).slope\n",
    "        if abs(slope) < threshold:\n",
    "            elapsed_time = times[i] - times[0]\n",
    "            print(f\"Reaction has reached plateau after {elapsed_time}\")\n",
    "            return (elapsed_time, i)\n",
    "    return (None, len(values) - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_folder_paths(parent_folder):\n",
    "    folder_paths = []\n",
    "    for dir in tqdm(os.scandir(parent_folder)):\n",
    "        if (\n",
    "            dir.is_dir()\n",
    "            and dir.name not in [\"processed\", \"averaged\"]\n",
    "            and \"STANDBY\" not in dir.name\n",
    "        ):\n",
    "            folder_paths.append(dir.path)\n",
    "    return folder_paths\n",
    "\n",
    "\n",
    "# specify the parent folder containing the experiment data\n",
    "parent_folder = os.path.join(\"DATAPATH\", exp_code)\n",
    "rm_folder = [dir for dir in os.listdir(parent_folder) if \"RM\" in dir][0]\n",
    "datapaths = get_folder_paths(os.path.join(parent_folder, rm_folder))\n",
    "print(f\"Found {len(datapaths)} datapaths in {rm_folder}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectrum.load_spectrum(datapaths[0], preprocessed=False)\n",
    "\n",
    "fid_ref = spectrum.y_data\n",
    "spectral_width = spectrum.udic[0][\"sw\"]\n",
    "print(\"Spectral width (Hz): \", spectral_width)\n",
    "\n",
    "# calculate sampling rate in Hz from x axis\n",
    "sampling_rate = 1 / (spectrum.x_data[1] - spectrum.x_data[0])\n",
    "print(\"Sampling rate (Hz): \", sampling_rate)\n",
    "\n",
    "# Assume fid is complex FID of the solvent peak\n",
    "phase = np.unwrap(np.angle(fid_ref))[:10000]\n",
    "time = np.arange(len(fid_ref))[:10000] / sampling_rate\n",
    "slope, intercept = np.polyfit(time, phase, 1)\n",
    "\n",
    "drift_Hz = slope / (2 * np.pi)\n",
    "print(\"Drift (Hz): \", drift_Hz)\n",
    "\n",
    "spectrum.default_processing()\n",
    "default_ppm = spectrum.x_data\n",
    "spectrum.find_peaks()\n",
    "spectrum.show_spectrum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.signal import correlate\n",
    "\n",
    "\n",
    "def cross_correlation_similarity(fid1, fid2):\n",
    "    # Zero-mean signals (optional, to remove DC bias)\n",
    "    fid1 = fid1 - np.mean(fid1)\n",
    "    fid2 = fid2 - np.mean(fid2)\n",
    "\n",
    "    # Full cross-correlation\n",
    "    corr = correlate(fid1, fid2, mode=\"full\")\n",
    "    max_corr = np.max(np.abs(corr))\n",
    "\n",
    "    # Normalize by autocorrelation to get similarity score\n",
    "    norm = np.sqrt(np.sum(np.abs(fid1) ** 2) * np.sum(np.abs(fid2) ** 2))\n",
    "    similarity = max_corr / norm\n",
    "\n",
    "    return similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "\n",
    "timestamps: list[int] = []\n",
    "raw_spectra: list[SpinsolveNMRSpectrum] = []\n",
    "fids: list[np.ndarray] = []\n",
    "similarities: list[float] = []\n",
    "\n",
    "for datapath in tqdm(datapaths):\n",
    "    spectrum.load_spectrum(datapath, preprocessed=False)\n",
    "    timestamps.append(spectrum.timestamp)\n",
    "    raw_spectra.append(deepcopy(spectrum))\n",
    "    fids.append(spectrum.y_data)\n",
    "\n",
    "    fid = spectrum.y_data\n",
    "    similarity = cross_correlation_similarity(fid_ref, fid)\n",
    "    similarities.append(similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "times_min = [(ts - timestamps[0]) / 60 for ts in timestamps]\n",
    "print(f\"Total experiment time: {times_min[-1]} min\")\n",
    "print(f\"Mean sampling interval: {np.mean(np.diff(times_min))*60} sec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nmrglue as ng\n",
    "\n",
    "processed_data = []\n",
    "for fid in fids:\n",
    "    # apodization\n",
    "    temp = ng.proc_base.gm(data=fid, g1=1.2 / spectral_width, g2=4.5 / spectral_width)\n",
    "    # zero-filling\n",
    "    temp = ng.proc_base.zf_double(data=temp, n=1)\n",
    "    # Fourier transform\n",
    "    temp = ng.proc_base.fft(data=temp)\n",
    "    processed_data.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from AnalyticalLabware.analysis.base_spectrum import GenericSpectrum\n",
    "from AnalyticalLabware.analysis.spec_utils import jaccard_two_spectra\n",
    "\n",
    "\n",
    "def trim_cut(x_axis, data, start_ppm: float, end_ppm: float, peaks: list[float]):\n",
    "    selector = (x_axis >= end_ppm) & (x_axis <= start_ppm)\n",
    "    x_axis = x_axis[selector]\n",
    "    data = data[selector]\n",
    "    for peak in peaks:\n",
    "        selector = (x_axis < peak - 0.5) | (x_axis > peak + 0.5)\n",
    "        x_axis = x_axis[selector]\n",
    "        data = data[selector]\n",
    "    return x_axis, data\n",
    "\n",
    "\n",
    "def get_jaccard_list(x_axis, data, ref_index=0, start_ppm=15, end_ppm=0):\n",
    "    PPM_PRECISION = 4\n",
    "    nmr_error = 1e3\n",
    "    SOLVENT_PEAKS = []\n",
    "\n",
    "    # process reference spectrum individually\n",
    "    ref_y = data[ref_index]\n",
    "    ref_x, ref_y = trim_cut(x_axis, data[ref_index], start_ppm, end_ppm, SOLVENT_PEAKS)\n",
    "\n",
    "    reference_spectrum = GenericSpectrum()\n",
    "    reference_spectrum.load_data(ref_x, ref_y, None)\n",
    "\n",
    "    print(\"Calculating Jaccard indices...\")\n",
    "    jaccards = []\n",
    "    for dataset in tqdm(data):\n",
    "        # process each spectrum\n",
    "        spectrum_x, spectrum_y = trim_cut(\n",
    "            x_axis, dataset, start_ppm, end_ppm, SOLVENT_PEAKS\n",
    "        )\n",
    "        spectrum = GenericSpectrum()\n",
    "        spectrum.load_data(spectrum_x, spectrum_y, None)\n",
    "        jaccards.append(\n",
    "            jaccard_two_spectra(reference_spectrum, spectrum, PPM_PRECISION, nmr_error)\n",
    "        )\n",
    "\n",
    "    return jaccards"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Moving average of single FIDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 16\n",
    "\n",
    "averaged_data = []\n",
    "for i, fid in enumerate(tqdm(fids)):\n",
    "    fid_ma = np.mean(\n",
    "        fids[max(0, i - window_size) : min(len(fids), i + window_size)], axis=0\n",
    "    )\n",
    "\n",
    "    # apodization\n",
    "    temp = ng.proc_base.gm(\n",
    "        data=fid_ma, g1=1.2 / spectral_width, g2=4.5 / spectral_width\n",
    "    )\n",
    "    # zero-filling\n",
    "    temp = ng.proc_base.zf_double(data=temp, n=1)\n",
    "    # Fourier transform\n",
    "    temp = ng.proc_base.fft(data=temp)\n",
    "    averaged_data.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jacc_con = get_jaccard_list(default_ppm, processed_data)\n",
    "jacc_ave = get_jaccard_list(default_ppm, averaged_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update(\n",
    "    {\n",
    "        \"font.size\": 24,\n",
    "        \"axes.linewidth\": 3,\n",
    "        \"xtick.major.width\": 3,\n",
    "        \"ytick.major.width\": 3,\n",
    "        \"xtick.minor.width\": 3,\n",
    "        \"ytick.minor.width\": 3,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "x_axis = times_min\n",
    "\n",
    "plt.plot(\n",
    "    x_axis, jacc_con, marker=\"o\", linestyle=\"None\", label=\"Conventional processing\"\n",
    ")\n",
    "\n",
    "plt.plot(x_axis, jacc_ave, marker=\"o\", linestyle=\"None\", label=\"Averaged processing\")\n",
    "\n",
    "plt.legend().get_frame().set_linewidth(3)\n",
    "\n",
    "plt.xlabel(\"Time / min\")\n",
    "plt.ylabel(\"Jaccard index\")\n",
    "plt.title(f\"Jaccard index from 0 to 15 ppm\")\n",
    "plt.savefig(\n",
    "    os.path.join(f\"{exp_code}_jaccard_full.svg\"),\n",
    "    dpi=300,\n",
    "    bbox_inches=\"tight\",\n",
    "    transparent=True,\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jacc_con_trim = get_jaccard_list(default_ppm, processed_data, start_ppm=7, end_ppm=5)\n",
    "jacc_ave_trim = get_jaccard_list(default_ppm, averaged_data, start_ppm=7, end_ppm=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "x_axis = times_min\n",
    "\n",
    "plt.plot(\n",
    "    x_axis, jacc_con_trim, marker=\"o\", linestyle=\"None\", label=\"Conventional processing\"\n",
    ")\n",
    "\n",
    "plt.plot(\n",
    "    x_axis, jacc_ave_trim, marker=\"o\", linestyle=\"None\", label=\"Averaged processing\"\n",
    ")\n",
    "\n",
    "plt.legend().get_frame().set_linewidth(3)\n",
    "\n",
    "plt.xlabel(\"Time / min\")\n",
    "plt.ylabel(\"Jaccard index\")\n",
    "plt.title(f\"Jaccard index from 5 to 7 ppm\")\n",
    "plt.savefig(\n",
    "    os.path.join(f\"{exp_code}_jaccard_5to7.svg\"),\n",
    "    dpi=300,\n",
    "    bbox_inches=\"tight\",\n",
    "    transparent=True,\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_peak(\n",
    "    wavelengths: np.ndarray, intensities: np.ndarray, peak: float, width: float\n",
    ") -> tuple[int, float, float]:\n",
    "    if len(wavelengths) != len(intensities):\n",
    "        raise ValueError(\"x_values and intensity must have the same length\")\n",
    "    selector = (wavelengths >= peak - width) & (wavelengths <= peak + width)\n",
    "    index_of_max_intensity = int(intensities[selector].argmax())\n",
    "    max_wavelength: float = wavelengths[selector][index_of_max_intensity]\n",
    "    max_intensity: float = intensities[selector][index_of_max_intensity]\n",
    "    return index_of_max_intensity, max_wavelength, max_intensity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peak_shifts = []\n",
    "for data in tqdm(averaged_data):\n",
    "    _, shift, _ = find_peak(default_ppm, data, peak=11, width=2)\n",
    "    peak_shifts.append(shift)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "plt.plot(times_min, peak_shifts, marker=\"o\", linestyle=\"None\")\n",
    "# plt.legend()\n",
    "ax.invert_yaxis()\n",
    "plt.xlabel(\"Time / min\")\n",
    "plt.ylabel(\"Peak position / ppm\")\n",
    "plt.title(f\"TCA peak position\")\n",
    "plt.savefig(\n",
    "    os.path.join(f\"{exp_code}_peak_shifts.svg\"),\n",
    "    dpi=300,\n",
    "    bbox_inches=\"tight\",\n",
    "    transparent=True,\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ave_similarities = []\n",
    "ave_fid_ref = None\n",
    "\n",
    "for i in tqdm(range(len(fids))):\n",
    "    fid_ma = np.mean(\n",
    "        fids[max(0, i - window_size) : min(len(fids), i + window_size)], axis=0\n",
    "    )\n",
    "    if ave_fid_ref is None:\n",
    "        ave_fid_ref = fid_ma\n",
    "\n",
    "    similarity = cross_correlation_similarity(ave_fid_ref, fid_ma)\n",
    "    ave_similarities.append(similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "# conventional processing\n",
    "plt.plot(\n",
    "    times_min,\n",
    "    similarities,\n",
    "    marker=\"o\",\n",
    "    linestyle=\"None\",\n",
    "    label=\"Conventional processing\",\n",
    ")\n",
    "\n",
    "# averaged processing\n",
    "plt.plot(\n",
    "    times_min,\n",
    "    ave_similarities,\n",
    "    marker=\"o\",\n",
    "    linestyle=\"None\",\n",
    "    label=\"Averaged processing\",\n",
    ")\n",
    "\n",
    "plt.legend().get_frame().set_linewidth(3)\n",
    "\n",
    "plt.xlabel(\"Time (min)\")\n",
    "plt.ylabel(\"Similarity\")\n",
    "plt.title(\"Cross correlation of FID data\")\n",
    "plt.savefig(\n",
    "    os.path.join(f\"{exp_code}_ave_FID_similarity.svg\"),\n",
    "    dpi=300,\n",
    "    bbox_inches=\"tight\",\n",
    "    transparent=True,\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xdl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
