{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from glob import glob\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HERE = os.path.abspath(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from AnalyticalLabware.analysis.spinsolve_spectrum import SpinsolveNMRSpectrum\n",
    "\n",
    "\n",
    "spectrum = SpinsolveNMRSpectrum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"Robert Rauschen\"\n",
    "exp_code = \"loph-3-v7\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_folder_paths(parent_folder):\n",
    "    folder_paths = []\n",
    "    for root, dirs, _ in tqdm(os.walk(parent_folder)):\n",
    "        for directory in dirs:\n",
    "            if \"processed\" not in directory and \"Enhanced\" not in directory:\n",
    "                folder_paths.append(os.path.join(root, directory))\n",
    "    return folder_paths\n",
    "\n",
    "\n",
    "# specify the parent folder containing the raw data folders\n",
    "parent_folder = os.path.join(\n",
    "    \"Y:\\\\data\\\\spinsolve80_ultra_multiX_SPA3681\", name, exp_code\n",
    ")\n",
    "datapaths = get_folder_paths(parent_folder)\n",
    "print(f\"Found {len(datapaths)} data files in {parent_folder}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# just for getting the total monitoring time\n",
    "timestamps = [filepath.split(\"\\\\\")[-1][:15] for filepath in datapaths]\n",
    "times = sorted(\n",
    "    [datetime.strptime(timestamp, \"%Y%m%d_%H%M%S\") for timestamp in timestamps]\n",
    ")\n",
    "print(\"Total experiment time: \", times[-1] - times[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROCESSED = os.path.join(parent_folder, \"processed\")\n",
    "\n",
    "if not os.path.exists(PROCESSED):\n",
    "    os.makedirs(PROCESSED)\n",
    "\n",
    "for datapath in tqdm(datapaths):\n",
    "    spectrum.load_spectrum(data_path=datapath)\n",
    "\n",
    "    spectrum.apodization(function=\"gm\", g1=1.2, g2=4.5)\n",
    "    spectrum.zero_fill()\n",
    "    spectrum.fft()\n",
    "    spectrum.reference_spectrum(new_position=1.8, reference=\"highest\")\n",
    "\n",
    "    spectrum.save_pickle(os.path.join(PROCESSED, os.path.basename(datapath)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_datafiles = sorted(glob(f\"{PROCESSED}/*\"))\n",
    "processed_datafiles = [file for file in processed_datafiles if file.endswith(\".pkl\")]\n",
    "timestamps = [filepath.split(\"\\\\\")[-1][:15] for filepath in processed_datafiles]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import linregress\n",
    "\n",
    "\n",
    "def detect_plateau_from_slope(\n",
    "    times, values, num_datapoints: int = 5, threshold: float = 1e-4\n",
    ") -> tuple:\n",
    "    \"\"\"\n",
    "    Detects a plateau in a list of values by calculating the slope of a linear regression\n",
    "    for the last num_datapoints and comparing it to a threshold value.\n",
    "    \"\"\"\n",
    "    for i in range(len(values) - num_datapoints):\n",
    "        if i < num_datapoints:\n",
    "            continue\n",
    "        slope = linregress(\n",
    "            range(num_datapoints),\n",
    "            np.array(values[i - num_datapoints : i]) / max(values),\n",
    "        ).slope\n",
    "        if abs(slope) < threshold:\n",
    "            elapsed_time = datetime.strptime(\n",
    "                times[i], \"%Y%m%d_%H%M%S\"\n",
    "            ) - datetime.strptime(times[0], \"%Y%m%d_%H%M%S\")\n",
    "            print(f\"Reaction has reached plateau after {elapsed_time}\")\n",
    "            return (elapsed_time, i)\n",
    "    return (None, len(values) - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an empty dictionary to store peak data\n",
    "peak_data = {}\n",
    "peak_1 = 7.6\n",
    "peak_2 = 7.3\n",
    "\n",
    "for datafile, timestamp in tqdm(zip(processed_datafiles, timestamps)):\n",
    "    spectrum = SpinsolveNMRSpectrum().from_pickle(datafile)\n",
    "\n",
    "    # Create a list to store peak areas for this timestamp\n",
    "    timestamp_peak_areas = {}\n",
    "\n",
    "    timestamp_peak_areas[peak_1] = spectrum.integrate_area((peak_1 + 0.1, peak_1 - 0.1))\n",
    "    timestamp_peak_areas[peak_2] = spectrum.integrate_area((peak_2 + 0.2, peak_2 - 0.2))\n",
    "\n",
    "    # Add the timestamp data to the dictionary\n",
    "    peak_data[timestamp] = timestamp_peak_areas\n",
    "\n",
    "# Create the DataFrame from the dictionary\n",
    "peak_areas = pd.DataFrame.from_dict(peak_data, orient=\"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update(\n",
    "    {\n",
    "        \"font.size\": 24,\n",
    "        \"axes.linewidth\": 3,\n",
    "        \"xtick.major.width\": 3,\n",
    "        \"ytick.major.width\": 3,\n",
    "        \"xtick.minor.width\": 3,\n",
    "        \"ytick.minor.width\": 3,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the ppm values for the peaks\n",
    "peak1_ppm = 7.6\n",
    "peak2_ppm = 7.3\n",
    "slope_threshold = 1e-3\n",
    "\n",
    "# create new dataframe with only the peaks of interest\n",
    "peak_areas_diagnostic = peak_areas[[peak1_ppm, peak2_ppm]]\n",
    "\n",
    "# drop the rows with NaN values from peak_areas\n",
    "peak_areas_diagnostic = peak_areas_diagnostic.dropna()\n",
    "\n",
    "# Extract the columns corresponding to the peaks of interest\n",
    "peak1_column = peak_areas_diagnostic[peak1_ppm]\n",
    "peak2_column = peak_areas_diagnostic[peak2_ppm]\n",
    "\n",
    "# Calculate the ratio of the peaks at each timestamp\n",
    "peak_ratio = peak2_column / (peak1_column + peak2_column)\n",
    "\n",
    "elapsed_time, plateau_index = detect_plateau_from_slope(\n",
    "    peak_areas_diagnostic.index, peak_ratio, num_datapoints=5, threshold=slope_threshold\n",
    ")\n",
    "\n",
    "formatted_times = sorted(\n",
    "    [\n",
    "        datetime.strptime(timestamp, \"%Y%m%d_%H%M%S\")\n",
    "        for timestamp in peak_areas_diagnostic.index\n",
    "    ]\n",
    ")\n",
    "formatted_times = [\n",
    "    (timestamp - formatted_times[0]).total_seconds() / 60\n",
    "    for timestamp in formatted_times\n",
    "]\n",
    "\n",
    "# Plot the peak ratio over time\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.plot(formatted_times, peak_ratio, marker=\"o\", linestyle=\"None\", markersize=10)\n",
    "plt.axvline(\n",
    "    x=formatted_times[plateau_index],\n",
    "    color=\"r\",\n",
    "    linestyle=\"--\",\n",
    "    label=f\"Plateau after {elapsed_time}\",\n",
    ")\n",
    "plt.xlabel(\"Time / min\")\n",
    "plt.ylabel(\"Conversion\")\n",
    "\n",
    "plt.yticks(np.round(np.arange(0.7, 0.9, 0.05), 2))\n",
    "plt.ylim(min(peak_ratio) - 0.01, max(peak_ratio) + 0.01)\n",
    "\n",
    "plt.legend()\n",
    "plt.savefig(\n",
    "    exp_code + \"_conversion.svg\", bbox_inches=\"tight\", dpi=300, transparent=True\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PPM_PRECISION = 4\n",
    "SOLVENT_PEAKS = [1.8]\n",
    "\n",
    "# ppm in reverse order because NMR convention is to have ppm decrease from left to right\n",
    "start_ppm, end_ppm = 9.0, 6.0\n",
    "\n",
    "timestamps = [filepath.split(\"\\\\\")[-1][:15] for filepath in processed_datafiles]\n",
    "\n",
    "# Save spectrum objects in a dict\n",
    "spectra = {}\n",
    "\n",
    "\n",
    "def highpass_filter(spectrum: SpinsolveNMRSpectrum, threshold: float, inplace=True):\n",
    "    s = spectrum\n",
    "    s.y_data = np.where(s.y_data.real > threshold, s.y_data.real, 0)\n",
    "    return s\n",
    "\n",
    "\n",
    "def cut(spectrum: SpinsolveNMRSpectrum, low_ppm: float, high_ppm: float, inplace=True):\n",
    "    s = spectrum\n",
    "    selector = (s.x_data < low_ppm) | (s.x_data > high_ppm)\n",
    "    s.x_data = s.x_data[selector]\n",
    "    s.y_data = s.y_data[selector]\n",
    "    return s\n",
    "\n",
    "\n",
    "def trim(spectrum: SpinsolveNMRSpectrum, low_ppm: float, high_ppm: float, inplace=True):\n",
    "    s = spectrum\n",
    "    selector = (s.x_data >= low_ppm) & (s.x_data <= high_ppm)\n",
    "    s.x_data = s.x_data[selector]\n",
    "    s.y_data = s.y_data[selector]\n",
    "    return s\n",
    "\n",
    "\n",
    "# process first spectrum individually to get common x-axis\n",
    "spectrum = SpinsolveNMRSpectrum().from_pickle(processed_datafiles[0])\n",
    "trim(spectrum, end_ppm, start_ppm)\n",
    "for solvent_peak in SOLVENT_PEAKS:\n",
    "    cut(spectrum, solvent_peak - 0.5, solvent_peak + 0.5)\n",
    "\n",
    "common_x_axis = np.round(spectrum.x_data, decimals=PPM_PRECISION)\n",
    "\n",
    "print(\"Creating array of spectra...\")\n",
    "spectra_array = np.zeros((len(processed_datafiles), len(common_x_axis)))\n",
    "for i in tqdm(range(len(processed_datafiles))):\n",
    "    spectrum = SpinsolveNMRSpectrum().from_pickle(processed_datafiles[i])\n",
    "    # highpass_filter(spectrum, HIGHPASS)\n",
    "    indices = np.digitize(common_x_axis, spectrum.x_data)\n",
    "    spectra_array[i] = spectrum.y_data.real[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.integrate import trapezoid\n",
    "\n",
    "nmr_error = 1e3\n",
    "\n",
    "\n",
    "# Calculate Jaccard index for pair of spectra\n",
    "def jaccard_next_two_spectra(index_1, index_2, reference_spectrum=None):\n",
    "    if reference_spectrum is None:\n",
    "        spectrum1_y = spectra_array[index_1]\n",
    "    else:\n",
    "        spectrum1_y = reference_spectrum\n",
    "    spectrum2_y = spectra_array[index_2]\n",
    "    union, intersection = [], []\n",
    "    for y1, y2 in zip(spectrum1_y, spectrum2_y):\n",
    "        if abs(y1 - y2) < nmr_error:\n",
    "            union.append(y2)\n",
    "            intersection.append(y2)\n",
    "        else:\n",
    "            union.append(max(y1, y2))\n",
    "            intersection.append(min(y1, y2))\n",
    "\n",
    "    intersection_area = trapezoid(intersection, common_x_axis)\n",
    "    union_area = trapezoid(union, common_x_axis)\n",
    "    return intersection_area / union_area\n",
    "\n",
    "\n",
    "print(\"Calculating Jaccard indices...\")\n",
    "jaccards = {}\n",
    "for i in tqdm(range(len(timestamps))):\n",
    "    jaccards[timestamps[i]] = jaccard_next_two_spectra(0, i)\n",
    "\n",
    "print(\"Calculating reverse Jaccard indices...\")\n",
    "reverse_jaccards = {}\n",
    "for i in tqdm(range(len(timestamps))):\n",
    "    reverse_jaccards[timestamps[i]] = jaccard_next_two_spectra(i, len(timestamps) - 1)\n",
    "\n",
    "print(\"Calclating neighbor Jaccard indices...\")\n",
    "neighbor_jaccards = {}\n",
    "for i in tqdm(range(len(timestamps) - 1)):\n",
    "    neighbor_jaccards[timestamps[i]] = jaccard_next_two_spectra(i, i + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elapsed_time, plateau_index = detect_plateau_from_slope(\n",
    "    list(jaccards.keys()), list(jaccards.values()), num_datapoints=5, threshold=1e-3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "times = [datetime.strptime(timestamp, \"%Y%m%d_%H%M%S\") for timestamp in jaccards.keys()]\n",
    "times_min = [(time - times[0]).total_seconds() / 60 for time in times]\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.plot(\n",
    "    times_min,\n",
    "    jaccards.values(),\n",
    "    marker=\"o\",\n",
    "    label=f\"Jaccard index {start_ppm} to {end_ppm} ppm\",\n",
    "    linestyle=\"None\",\n",
    "    markersize=10,\n",
    ")\n",
    "# plot vertical line at plateau index\n",
    "plt.axvline(\n",
    "    x=times_min[plateau_index],\n",
    "    color=\"r\",\n",
    "    linestyle=\"--\",\n",
    "    label=f\"Plateau after {elapsed_time}\",\n",
    ")\n",
    "\n",
    "plt.legend().get_frame().set_linewidth(3)\n",
    "\n",
    "plt.xlabel(\"Time / min\")\n",
    "plt.ylabel(\"Jaccard index\")\n",
    "plt.yticks(np.round(np.arange(0.7, 1.0, 0.1), 1))\n",
    "plt.ylim(min(jaccards.values()) - 0.01, max(jaccards.values()) + 0.01)\n",
    "\n",
    "plt.savefig(f\"{exp_code}_jaccard.svg\", bbox_inches=\"tight\", dpi=300, transparent=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\n",
    "    exp_code + \"_plotdata_jaccard.csv\",\n",
    "    np.column_stack((times_min, list(jaccards.values()))),\n",
    "    header=\"Time, Jaccard index\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import curve_fit\n",
    "\n",
    "PLATEAU_THRESHOLD_MARGIN = 0.01\n",
    "PLATEAU_DATAPOINTS = 5\n",
    "\n",
    "# exclude outliers with jaccard index < 0.1 from jaccards dict\n",
    "jaccards_filtered = {k: v for k, v in jaccards.items() if v >= 0.0}\n",
    "times = [\n",
    "    datetime.strptime(timestamp, \"%Y%m%d_%H%M%S\")\n",
    "    for timestamp in jaccards_filtered.keys()\n",
    "]\n",
    "\n",
    "datapoints = np.array(list(jaccards_filtered.values()))\n",
    "\n",
    "\n",
    "# Define fit function for reaction of first order (exponential decay)\n",
    "def exp_decay(x, a, b, c):\n",
    "    return a * np.exp(-b * x) + c\n",
    "\n",
    "\n",
    "# Define fit function for reaction of second order\n",
    "def second_order(x, a, b, c):\n",
    "    return 1 / (1 / a + b * x) + c\n",
    "\n",
    "\n",
    "# Convert the timestamps to elapsed time in seconds\n",
    "elapsed_time_sec = np.array([(time - times[0]).total_seconds() for time in times])\n",
    "\n",
    "# Fit the exponential decay function to the Jaccard index time series\n",
    "popt1, pcov1 = curve_fit(exp_decay, elapsed_time_sec, datapoints, p0=(1, 1e-3, 0.5))\n",
    "\n",
    "# Fit the second order function to the Jaccard index time series\n",
    "popt2, pcov2 = curve_fit(second_order, elapsed_time_sec, datapoints, p0=(1, 1e-3, 0.5))\n",
    "\n",
    "# find out where the plateau starts\n",
    "# check if 5 datapoints in a row are within 1% of the c parameter of the fitted function\n",
    "# if so, the reaction has reached the plateau\n",
    "plateau_index = len(datapoints) - 1\n",
    "elapsed_time = None\n",
    "for i in range(len(datapoints) - PLATEAU_DATAPOINTS):\n",
    "    if i < PLATEAU_DATAPOINTS:\n",
    "        continue\n",
    "    if all(\n",
    "        abs(datapoints[i - PLATEAU_DATAPOINTS : i] - popt1[2])\n",
    "        < PLATEAU_THRESHOLD_MARGIN\n",
    "    ):\n",
    "        print(i)\n",
    "        print(f\"Reaction has reached plateau at {list(jaccards.keys())[i]}\")\n",
    "        plateau_index = i\n",
    "        elapsed_time = times[plateau_index] - times[0]\n",
    "        break\n",
    "\n",
    "# Plot the fitted function\n",
    "plt.plot(\n",
    "    times_min,\n",
    "    exp_decay(elapsed_time_sec, *popt1),\n",
    "    \"r-\",\n",
    "    label=\"fit 1st: a=%.3f, b=%.3e, c=%.3f\" % tuple(popt1),\n",
    ")\n",
    "plt.plot(times_min, jaccards.values(), marker=\"o\", linestyle=\"None\")\n",
    "plt.axvline(\n",
    "    x=times_min[plateau_index],\n",
    "    color=\"r\",\n",
    "    linestyle=\"--\",\n",
    "    label=f\"Plateau after {elapsed_time}\",\n",
    ")\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend()\n",
    "plt.xlabel(\"Time / min\")\n",
    "plt.ylabel(\"Jaccard index\")\n",
    "plt.title(f\"Jaccard index for {exp_code}\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xdl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
